
---
title: "Data Visualization"
author: "Rachel Fellman"
date: "2024-07-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(modeldata)
library(corrplot)
#library(MASS)
library(glmnet)
```

Clean data
```{r}
data("hotel_rates")
hotel_rates
```
```{r}
#change certain rows to factors
myhotel<- hotel_rates %>% 
  mutate(is_repeated_guest = as.factor(is_repeated_guest), previous_cancellations,
         near_christmas = as.factor(near_christmas),
         near_new_years = as.factor(near_new_years)) %>% 
      #take out historical_adr variable since it is not part of the original data
  dplyr::select(- historical_adr)
```

# Data visualization


ggplot(myhotel) aes(x = lead_time, y = avg_price_per_room)) + 
  geom_point(aes(color = as.factor(is_repeated_guest)))+
  scale_fill_discrete(name = "Is Repeated Guest?", labels = c("No","Yes"))

# plot 1

Scatter plot of `avg_price_per_room` vs `lead_time` (Number of days that elapsed between the entering date of the booking into the PMS and the arrival date) colored by `customer_type`.
```{r}
#make base plot
g<- ggplot(myhotel, aes(x = lead_time, y = avg_price_per_room))
#add layers
g+ geom_point(aes(color = customer_type))+
  labs(x = "lead time (days)", y = "Average Room Price (euros)")
  
```

This is a scatter plot of average room rate in euros compared to the number of days between entering the date of booking into the system and the guest's arrival date. The points are colored by customer type. It appears that the majority of bookings are transient meaning they are not associated with a group or contract. From this plot we can see that there is a slightly negative relationship between lead time and room rate.


## plot 2
bar graph of `room_type` colored by `market_segment`
```{r}
#define base plot
g<- ggplot(myhotel, aes(x = reserved_room_type))
 g+ geom_bar(aes(fill= market_segment))+
  labs(x = "Room type", title = "Count of Room Type by Market Segment")
```
There appears to be a much higher count of room type a than any of the other room types. Due to the necessity of anonymity, we do not have access to what room type a is. From this graph, it also seems that the majority of all room types are from online travel agents.


## plot 3


Boxplot of `stays_in_week_nights` by `meal`

```{r}
g <- ggplot(myhotel, aes(x = meal, y = avg_price_per_room))
g + geom_boxplot(fill = "blue")
```

From these boxplots we can see the average room price is affected by the type of meal packages selected by the customer. This makes sense since the room charge includes the meals.


# plot 4
scatterplot of arrival date vs avg_price_per_room colored by room type.
```{r}
g<- ggplot(myhotel)
g+geom_jitter(aes(y = avg_price_per_room, x = arrival_date_num, color = assigned_room_type))
```
The relationship between avg_price_per_room and arrival_date does not appear to be linear, but rather is quadratic. It's hard to say without knowing a lot about the hotel business and tourism why room prices were generally lower in the beginning of 2017 versus other times. We can also see from this graph that certain room types are consistently higher priced than others, so room type is likely a good predictor of price.


```{r}
hotel3<- hotel2 %>% 
  mutate(total = adults+children+babies)
```


```{r}
g <- ggplot(hotel3)
g+geom_jitter(aes(y = stays_in_week_nights, x =total, color = market_segment))+
  labs(x = "Total Number of Guests (adults, children, & babies)", y="Number Of Week Nights Guest Booked", title = "Total Guest Count vs. Length of Week Night Stay Colored by Market Segment")
  
```

```{r}
g <- ggplot(hotel3)
g+geom_jitter(aes(y = stays_in_weekend_nights, x =total, color = market_segment))+
  labs(x = "Total Number of Guests (adults, children, & babies)", y="Number Of Weekend Nights Guest Booked", title = "Total Guest Count vs. Length of Weekend Night Stay Colored by Room Type")
```










```{r}
ggplot(myhotel, aes(x=is_repeated_guest, y=avg_price_per_room)) +
  geom_jitter(alpha=0.1, color="blue") +
  geom_boxplot(outlier.color="red") +
  labs(x="Repeat Guest", y="Average Room Price", title="Boxplot of Repeat Customers and Average Room Price") + 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```



# correlation plots for numeric variables

```{r}
#filter data to include only numeric variables
myhotel.num <- myhotel %>% 
  select(avg_price_per_room,lead_time,stays_in_weekend_nights,stays_in_week_nights,adults,children,babies,previous_cancellations,previous_bookings_not_canceled,booking_changes,days_in_waiting_list,required_car_parking_spaces,total_of_special_requests,arrival_date_num)
```


```{r}
#create correlation matrix
cor.mat <- cor(myhotel.num)
```

```{r}
#plot correlation matrix
ggcorrplot::ggcorrplot(cor.mat,
           type = "lower", #looks at just half of the matrix
           method = "circle")  #change to circle
```
From this correlation plot, we can see that there is a surprisingly high correlation between stays in weeknights and stays in weekend nights. All other variables do not appear to be highly correlated.



# check linear model assumptions

## make residual plot
```{r}
# make model with all variables
model1 <- lm(avg_price_per_room~., data = myhotel)
```

```{r}
#add predictions and residuals to our dataframe to make residual plot
hotel.pred <- mutate(myhotel, pred = fitted(model1), resid = residuals(model1))
```

```{r}
#make residual plot
ggplot(hotel.pred, aes(x=pred, y = resid))+geom_point()+geom_hline(yintercept = 0, color = "red")
```


This does not fit the necessary assumptions for linear modeling. There is a clear pattern to the data and the points do not appear to be randomly scattered.
We will try transforming the data  with a log transformation to better meet the assumptions.

## transform data and make residual plot again
```{r}
#do log transformation on avg_price_per_room
hotel2 <- mutate(myhotel, avg_price_per_room = log(avg_price_per_room))
```

```{r}
ggplot()
```


```{r}

hotel_df <- hotel2 %>%
  mutate(julian_date = yday(arrival_date)) %>%
  dplyr::select(-arrival_date)
```

### Model Selection

#### classic lm function (global F-test and individual T-tests)

```{r}
model1 <- lm(avg_price_per_room~., data=hotel_df)
summary(model1)
```


```{r}
#fit model again with log transformed data
model2<- lm(avg_price_per_room~., data = hotel2)
```

```{r}
summary(model2)
```


```{r}
#add predictions and residuals to our dataframe to make residual plot
hotel2.pred <- mutate(hotel2, pred = fitted(model2), resid = residuals(model2))
```

```{r}
#make residual plot

ggplot(hotel2.pred, aes(x=pred, y = resid))+geom_point()+geom_hline(yintercept = 0, color = "red")
```

After the log transformation, tht residuals are spread more evenly around the red line and there is no longer an obvious pattern. Therefore, our data meets the linearity assumption, the independence assumption and the equal variance assumption.


## make qq plot

```{r}
ggplot(hotel2.pred, aes(sample= resid))+stat_qq() +stat_qq_line()
```
Since the points in the qq plot follow the diagonal line, we have met the normal population assumption.





# variable selection using stepAIC function

We will do direction = both to use both forward and backwards selection
```{r}
aic <- stepAIC(model2, direction = "both")
```
```{r}
summary(aic)
```

Our final model when using aic variable selection is:  
avg_price_per_room ~ lead_time + stays_in_week_nights + 
    adults + children + babies + meal + country + market_segment + 
    distribution_channel + is_repeated_guest + previous_cancellations + 
    reserved_room_type + assigned_room_type + agent + customer_type + 
    required_car_parking_spaces + total_of_special_requests + 
    arrival_date + near_christmas + near_new_years
    
This model has an adjusted R^2 of .5206


# model with all variables
```{r}
summary(model2)
```
Our model with all the variables present has an r^2 of .5254.
This is higher than the model chosen with forward and backwards selection so perhaps this is a better model.



#fit models using carat package






```{r}
# Define the grid of alpha and lambda values
grid <- expand.grid(alpha = 1,  # Lasso regression
                    lambda = seq(-0.0001, 1, length.out = 100))
# Set up training control
train_control <- trainControl(method = "cv", number = 3)


```



```{r}
fit.lasso <- train(avg_price_per_room ~ ., 
                   data= hotel2,
                   #select glmnet method
                   method= "glmnet",
                   #train control
                   train_control = train_control,
                   #calculate rmse metric
                   metric= "RMSE",
                   #add tuning parameters
                   tuneGrid= grid)
```
```{r}
fit.lasso
```


```{r}
fit.lasso$finalModel$xNames
```
When we look at the final model for our lasso model, all of the predictors are also present.


```{r}
fit.lasso$results$Rsquared
```


```{r}
predictions_lasso <- fit.lasso %>% predict(testData)
```

#get r^2 for lasso model
```{r}
Lasso_R2 = R2(predictions_lasso, testData$avg_price_per_room)
Lasso_R2
```

When we get the r^2 value for the lasso model when used on our test set, we get a value of .5062294. This is lower than our other 2 models.


For our final model we will chose to include all the predictor variables







```{r}
levels(myhotel$meal)
```





# fit lasso models with glmnet package

## make design matrix
```{r}
X <- model.matrix(avg_price_per_room~0+.,hotel2) 
y<- hotel2$avg_price_per_room
```

## run lasso model
```{r}
lasso.mod <- glmnet(x=X,y=y, alpha =1)

```


## do lasso with cross validation
```{r}

lasso.cv <-  cv.glmnet(x=X,y=y,alpha=1,nfolds = 10)
```

```{r}
lasso.cv$lambda.1se
```


## plot lasso model
```{r}
plot(lasso.mod, label = TRUE, xvar = "lambda")+abline(v=log(lasso.cv$lambda.1se))

```


=======
---
title: "Data Visualization"
author: "Rachel Fellman"
date: "2024-07-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(modeldata)
library(corrplot)
#library(MASS)
library(glmnet)
```

Clean data
```{r}
data("hotel_rates")
hotel_rates
```
```{r}
#change certain rows to factors
myhotel<- hotel_rates %>% 
  mutate(is_repeated_guest = as.factor(is_repeated_guest), previous_cancellations,
         near_christmas = as.factor(near_christmas),
         near_new_years = as.factor(near_new_years)) %>% 
      #take out historical_adr variable since it is not part of the original data
  dplyr::select(- historical_adr)
```

# Data visualization


ggplot(myhotel) aes(x = lead_time, y = avg_price_per_room)) + 
  geom_point(aes(color = as.factor(is_repeated_guest)))+
  scale_fill_discrete(name = "Is Repeated Guest?", labels = c("No","Yes"))

# plot 1

Scatter plot of `avg_price_per_room` vs `lead_time` (Number of days that elapsed between the entering date of the booking into the PMS and the arrival date) colored by `customer_type`.
```{r}
#make base plot
g<- ggplot(myhotel, aes(x = lead_time, y = avg_price_per_room))
#add layers
g+ geom_point(aes(color = customer_type))+
  labs(x = "lead time (days)", y = "Average Room Price (euros)")
  
```

This is a scatter plot of average room rate in euros compared to the number of days between entering the date of booking into the system and the guest's arrival date. The points are colored by customer type. It appears that the majority of bookings are transient meaning they are not associated with a group or contract. From this plot we can see that there is a slightly negative relationship between lead time and room rate.


## plot 2
bar graph of `room_type` colored by `market_segment`
```{r}
#define base plot
g<- ggplot(myhotel, aes(x = reserved_room_type))
 g+ geom_bar(aes(fill= market_segment))+
  labs(x = "Room type", title = "Count of Room Type by Market Segment")
```
There appears to be a much higher count of room type a than any of the other room types. Due to the necessity of anonymity, we do not have access to what room type a is. From this graph, it also seems that the majority of all room types are from online travel agents.


## plot 3


Boxplot of `stays_in_week_nights` by `meal`

```{r}
g <- ggplot(myhotel, aes(x = meal, y = avg_price_per_room))
g + geom_boxplot(fill = "blue")
```

From these boxplots we can see the average room price is affected by the type of meal packages selected by the customer. This makes sense since the room charge includes the meals.


# plot 4
scatterplot of arrival date vs avg_price_per_room colored by room type.
```{r}
g<- ggplot(myhotel)
g+geom_jitter(aes(y = avg_price_per_room, x = arrival_date_num, color = assigned_room_type))
```
The relationship between avg_price_per_room and arrival_date does not appear to be linear, but rather is quadratic. It's hard to say without knowing a lot about the hotel business and tourism why room prices were generally lower in the beginning of 2017 versus other times. We can also see from this graph that certain room types are consistently higher priced than others, so room type is likely a good predictor of price.


```{r}
hotel3<- hotel2 %>% 
  mutate(total = adults+children+babies)
```


```{r}
g <- ggplot(hotel3)
g+geom_jitter(aes(y = stays_in_week_nights, x =total, color = market_segment))+
  labs(x = "Total Number of Guests (adults, children, & babies)", y="Number Of Week Nights Guest Booked", title = "Total Guest Count vs. Length of Week Night Stay Colored by Market Segment")
  
```

```{r}
g <- ggplot(hotel3)
g+geom_jitter(aes(y = stays_in_weekend_nights, x =total, color = market_segment))+
  labs(x = "Total Number of Guests (adults, children, & babies)", y="Number Of Weekend Nights Guest Booked", title = "Total Guest Count vs. Length of Weekend Night Stay Colored by Room Type")
```










```{r}
ggplot(myhotel, aes(x=is_repeated_guest, y=avg_price_per_room)) +
  geom_jitter(alpha=0.1, color="blue") +
  geom_boxplot(outlier.color="red") +
  labs(x="Repeat Guest", y="Average Room Price", title="Boxplot of Repeat Customers and Average Room Price") + 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```



# correlation plots for numeric variables

```{r}
#filter data to include only numeric variables
myhotel.num <- myhotel %>% 
  select(avg_price_per_room,lead_time,stays_in_weekend_nights,stays_in_week_nights,adults,children,babies,previous_cancellations,previous_bookings_not_canceled,booking_changes,days_in_waiting_list,required_car_parking_spaces,total_of_special_requests,arrival_date_num)
```


```{r}
#create correlation matrix
cor.mat <- cor(myhotel.num)
```

```{r}
#plot correlation matrix
ggcorrplot::ggcorrplot(cor.mat,
           type = "lower", #looks at just half of the matrix
           method = "circle")  #change to circle
```
From this correlation plot, we can see that there is a surprisingly high correlation between stays in weeknights and stays in weekend nights. All other variables do not appear to be highly correlated.



# check linear model assumptions

## make residual plot
```{r}
# make model with all variables
model1 <- lm(avg_price_per_room~., data = myhotel)
```

```{r}
#add predictions and residuals to our dataframe to make residual plot
hotel.pred <- mutate(myhotel, pred = fitted(model1), resid = residuals(model1))
```

```{r}
#make residual plot
ggplot(hotel.pred, aes(x=pred, y = resid))+geom_point()+geom_hline(yintercept = 0, color = "red")
```


This does not fit the necessary assumptions for linear modeling. There is a clear pattern to the data and the points do not appear to be randomly scattered.
We will try transforming the data  with a log transformation to better meet the assumptions.

## transform data and make residual plot again
```{r}
#do log transformation on avg_price_per_room
hotel2 <- mutate(myhotel, avg_price_per_room = log(avg_price_per_room))
```

```{r}
ggplot()
```


```{r}

hotel_df <- hotel2 %>%
  mutate(julian_date = yday(arrival_date)) %>%
  dplyr::select(-arrival_date)
```

### Model Selection

#### classic lm function (global F-test and individual T-tests)

```{r}
model1 <- lm(avg_price_per_room~., data=hotel_df)
summary(model1)
```


```{r}
#fit model again with log transformed data
model2<- lm(avg_price_per_room~., data = hotel2)
```

```{r}
summary(model2)
```


```{r}
#add predictions and residuals to our dataframe to make residual plot
hotel2.pred <- mutate(hotel2, pred = fitted(model2), resid = residuals(model2))
```

```{r}
#make residual plot

ggplot(hotel2.pred, aes(x=pred, y = resid))+geom_point()+geom_hline(yintercept = 0, color = "red")
```

After the log transformation, tht residuals are spread more evenly around the red line and there is no longer an obvious pattern. Therefore, our data meets the linearity assumption, the independence assumption and the equal variance assumption.


## make qq plot

```{r}
ggplot(hotel2.pred, aes(sample= resid))+stat_qq() +stat_qq_line()
```
Since the points in the qq plot follow the diagonal line, we have met the normal population assumption.





# variable selection using stepAIC function

We will do direction = both to use both forward and backwards selection
```{r}
aic <- stepAIC(model2, direction = "both")
```
```{r}
summary(aic)
```

Our final model when using aic variable selection is:  
avg_price_per_room ~ lead_time + stays_in_week_nights + 
    adults + children + babies + meal + country + market_segment + 
    distribution_channel + is_repeated_guest + previous_cancellations + 
    reserved_room_type + assigned_room_type + agent + customer_type + 
    required_car_parking_spaces + total_of_special_requests + 
    arrival_date + near_christmas + near_new_years
    
This model has an adjusted R^2 of .5206


# model with all variables
```{r}
summary(model2)
```
Our model with all the variables present has an r^2 of .5254.
This is higher than the model chosen with forward and backwards selection so perhaps this is a better model.



#fit models using carat package






```{r}
# Define the grid of alpha and lambda values
grid <- expand.grid(alpha = 1,  # Lasso regression
                    lambda = seq(-0.0001, 1, length.out = 100))
# Set up training control
train_control <- trainControl(method = "cv", number = 3)


```



```{r}
fit.lasso <- train(avg_price_per_room ~ ., 
                   data= hotel2,
                   #select glmnet method
                   method= "glmnet",
                   #train control
                   train_control = train_control,
                   #calculate rmse metric
                   metric= "RMSE",
                   #add tuning parameters
                   tuneGrid= grid)
```
```{r}
fit.lasso
```


```{r}
fit.lasso$finalModel$xNames
```
When we look at the final model for our lasso model, all of the predictors are also present.


```{r}
fit.lasso$results$Rsquared
```


```{r}
predictions_lasso <- fit.lasso %>% predict(testData)
```

#get r^2 for lasso model
```{r}
Lasso_R2 = R2(predictions_lasso, testData$avg_price_per_room)
Lasso_R2
```

When we get the r^2 value for the lasso model when used on our test set, we get a value of .5062294. This is lower than our other 2 models.


For our final model we will chose to include all the predictor variables







```{r}
levels(myhotel$meal)
```





# fit lasso models with glmnet package

## make design matrix
```{r}
X <- model.matrix(avg_price_per_room~0+.,hotel2) 
y<- hotel2$avg_price_per_room
```

## run lasso model
```{r}
lasso.mod <- glmnet(x=X,y=y, alpha =1)

```


## do lasso with cross validation
```{r}

lasso.cv <-  cv.glmnet(x=X,y=y,alpha=1,nfolds = 10)
```

```{r}
lasso.cv$lambda.1se
```


## plot lasso model
```{r}
plot(lasso.mod, label = TRUE, xvar = "lambda")+abline(v=log(lasso.cv$lambda.1se))

```

